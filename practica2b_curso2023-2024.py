"""
Pr√°ctica 2a: Obteniendo m√°ximos y m√≠nimos en dos dimensiones
con distintos m√©todos
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import RectBivariateSpline
from optimization import razon_aurea_maximizar

# --------------------------------------------------Ejercicio 1----------------------------------------------------------
"""
Importar y representar el fichero de datos en 3 dimensiones, y tambi√©n en 2 dimensiones
con imshow.
"""
# Creamos un grid para la representaci√≥n de los datos
N = 121
xmax = 3
xmin = -3
x = np.linspace(xmin, xmax, N)
y = np.linspace(xmin, xmax, N)
data_x, data_y = np.meshgrid(x, y)
data_z = np.loadtxt('data_practica_2.txt', float)  # importamos los datos

# Representaci√≥n en 3D de la funci√≥n
fig, ax = plt.subplots(subplot_kw={'projection': '3d'})
surface = ax.plot_surface(data_x, data_y, data_z, cmap='terrain')
fig.colorbar(surface, label="z")  # Agregar etiqueta a la barra de color
ax.set_title("Altura monta√±as")  # T√≠tulo del gr√°fico
ax.set_xlabel("x (eje de las abscisas)")  # Etiqueta para el eje x
ax.set_ylabel("y (eje de las ordenadas)")  # Etiqueta para el eje y
ax.set_zlabel("z (altura)")  # Etiqueta para el eje z
plt.show()

# Representaci√≥n en 2D de la funci√≥n
plt.imshow(data_z, origin='lower', cmap='terrain', extent=(-3, 3, -3, 3))
plt.colorbar(label="z")  # Agregar etiqueta a la barra de color
plt.title("Altura monta√±as")  # T√≠tulo del gr√°fico
plt.xlabel("x (eje de las abscisas)")  # Etiqueta para el eje x
plt.ylabel("y (eje de las ordenadas)")  # Etiqueta para el eje y
plt.show()

# --------------------------------------------------Ejercicio 2----------------------------------------------------------
""""
Definir una funci√≥n interpoladora de los puntos del fichero por medio de splines
c√∫bicos. Para ello, hacer uso de la funci√≥n RectBivariateSpline de scipy.interpolate
"""
f_z = RectBivariateSpline(x, y, data_z.T)
# --------------------------------------------------Ejercicio 3----------------------------------------------------------
"""
Realizar la representaci√≥n de densidad de la funci√≥n del apartado anterior en ‚àí3 ‚â§
ùë• ‚â§ 3, ‚àí3 ‚â§ ùë¶ ‚â§ 3 en un grid 1000 √ó 1000. Adem√°s, elegir un punto inicial para calcular el
m√°ximo global en dicho dominio, y a√±adirlo a la representaci√≥n.
"""
N = 1000
xmax = 3
xmin = -3
x_prima = np.linspace(xmin, xmax, N)
y_prima = np.linspace(xmin, xmax, N)
pto_inicial_maximo_global = np.array([1.5, -1.4])
"""
Ayuda:
- En el imshow, basta introducir f(x‚Äô,y‚Äô).T donde x‚Äô e y‚Äô son los arrays creados para la representaci√≥n (no hay que usar meshgrid).
- Se recomienda utilizar en imshow la opci√≥n extent para representar con facilidad el punto inicial escogido.
"""
# Representaci√≥n en 2D de la funci√≥n con punto inicial
plt.imshow(f_z(x_prima, y_prima).T, origin='lower', cmap='terrain', extent=(-3, 3, -3, 3))
plt.scatter(pto_inicial_maximo_global[0], pto_inicial_maximo_global[1])
plt.colorbar(label="z")  # Agregar etiqueta a la barra de color
plt.title("Altura monta√±as (con punto inicial)")  # T√≠tulo del gr√°fico
plt.xlabel("x (eje de las abscisas)")  # Etiqueta para el eje x
plt.ylabel("y (eje de las ordenadas)")  # Etiqueta para el eje y
plt.show()

# --------------------------------------------------Ejercicio 4----------------------------------------------------------
"""
Implementar el m√©todo de m√°xima pendiente para funciones de dos variables con el
fin de encontrar un m√°ximo con una precisi√≥n de 10‚àí5. El c√°lculo del gradiente deber√° hacerse
con diferencias centradas, con paso ‚Ñé = 10‚àí3 para ambas variables, y utilizar el m√©todo de
la raz√≥n √°urea para la maximizaci√≥n en una variable. ¬øPor qu√© es preferible al m√©todo de
Gauss-Newton? -> es preferible porque no se puede calcular la segunda derivada
"""
eps = 1e-5


def gradiente_diferencias_centradas(f, x, y):
    h = 1e-3
    grad = [0, 0]
    grad[0] = (f(x + h / 2, y) - f(x - h / 2, y)) / h
    grad[1] = (f(x, y + h / 2) - f(x, y - h / 2)) / h
    return grad


def maxima_pendiente(f: 'funcion', x0: 'pto x inicial', y0: 'pto y inicial', prec: 'precision objetivo') -> 'Extremo':
    err = 1
    cont = 0
    while err > prec:
        v = gradiente_diferencias_centradas(f, x0, y0)
        norm_v = (v[0] ** 2 + v[1] ** 2) ** (1 / 2)

        def f_2(k):
            return f(x0 + k * v[0] / norm_v, y0 + k * v[1] / norm_v)

        k = razon_aurea_maximizar(f_2, -1.5, 1.5,
                                  prec)  # Los valores de x1 y x4 hay que "tunearlos" dependiendo de la estimaci√≥n inicial.
        x1, y1 = x0 + k * v[0] / norm_v, y0 + k * v[1] / norm_v
        err = ((x1 - x0) ** 2 + (y1 - y0) ** 2) ** (1 / 2)
        cont += 1
        plt.plot(x1, y1, 'r.')
        plt.arrow(x0, y0, x1 - x0, y1 - y0, length_includes_head=True, head_width=0.1, head_length=0.05, color='k')
        x0, y0 = x1, y1
        print('Se han necesitado', str(cont), 'iteraciones para llegar al m√°ximo:')
        print('x=', x1, ' , y=', y1, sep="")
        print()
    return x1, y1


# --------------------------------------------------Ejercicio 5----------------------------------------------------------
"""
Aplicar el m√©todo de la m√°xima pendiente a la funci√≥n definida en el apartado 2
para obtener su m√°ximo global en ‚àí3 ‚â§ ùë• ‚â§ 3, ‚àí3 ‚â§ ùë¶ ‚â§ 3. A√±adir a la representaci√≥n
de densidad del apartado 3 las iteraciones que se han obtenido (para ello, puede modificarse
levemente la funci√≥n del apartado anterior).

Ayuda: Por el funcionamiento de RectBivariateSpline, al evaluar la funci√≥n interpoladora
ùëì en un punto, se nos proporciona la evaluaci√≥n de la funci√≥n dentro de un array. Por ello
se recomienda definir una funci√≥n que evaluada en un punto (ùë•, ùë¶), devuelva ùëì(ùë•, ùë¶)[0][0], y
maximizar dicha funci√≥n.
"""
# Estimaci√≥n inicial
x0, y0 = 1.5, -0.5


# Siguiendo la ayuda, vamos a maximizar la siguiente funci√≥n
def f_z_3(x, y):
    return f_z(x, y)[0][0]


# Repetimos el plot del apartado 3
plt.imshow(f_z(x_prima, y_prima).T, cmap='terrain', extent=(-3, 3, -3, 3), origin='lower')
plt.plot(x0, y0, 'b.')
plt.colorbar()

xf, yf = maxima_pendiente(f_z_3, x0, y0, eps)
plt.plot(xf, yf, 'g.')  # A√±adimos en verde el m√°ximo obtenido
plt.title('Maxima pendiente')
plt.show()
# --------------------------------------------------Ejercicio 6---------------------------------------------------------
"""
Repetir el apartado anterior con otros puntos iniciales para obtener los otros m√°ximos
relativos. ¬øQu√© pasa si se coge como punto inicial el origen?¬øY si nos desplazamos de √©l un
poco?
"""
# Repetimos el apartado anterior con puntos en torno al origen
# para alcanzar el resto de m√°ximos relativos
x0, y0 = 0, 0
x01, y01 = 0.1, 0
x02, y02 = -0.1, 0
x03, y03 = 0, 0.1
x04, y04 = 0, -0.1
x05, y05 = -0.1, 0.1
plt.imshow(f_z(x_prima, y_prima).T, cmap='terrain', extent=(-3, 3, -3, 3), origin='lower')
plt.plot(x0, y0, 'b.')
plt.plot(x01, y01, 'b.')
plt.plot(x02, y02, 'b.')
plt.plot(x03, y03, 'b.')
plt.plot(x04, y04, 'b.')
plt.plot(x05, y05, 'b.')
plt.colorbar()
xf, yf = maxima_pendiente(f_z_3, x0, y0, eps)
plt.plot(xf, yf, 'g.')
xf, yf = maxima_pendiente(f_z_3, x01, y01, eps)
plt.plot(xf, yf, 'g.')
xf, yf = maxima_pendiente(f_z_3, x02, y02, eps)
plt.plot(xf, yf, 'g.')
xf, yf = maxima_pendiente(f_z_3, x03, y03, eps)
plt.plot(xf, yf, 'g.')
xf, yf = maxima_pendiente(f_z_3, x04, y04, eps)
plt.plot(xf, yf, 'g.')
xf, yf = maxima_pendiente(f_z_3, x05, y05, eps)
plt.plot(xf, yf, 'g.')
plt.title('M√°xima pendiente')
plt.show()
# --------------------------------------------------Ejercicio 7 (extra)-------------------------------------------------
"""
Implementar el m√©todo del gradiente conjugado, y aplicarlo a la funci√≥n de apartado
2 para los mismos puntos iniciales. A√±adir a la representaci√≥n del apartado 3 las iteraciones
obtenidas. ¬øQu√© diferencias observas respecto al m√©todo de la m√°xima pendiente?
"""


def gradiente_conjugado_fletcher_reeves(f, x0, y0, prec):
    err = 1
    v_old = gradiente_diferencias_centradas(f, x0, y0)
    norm_v_old = (v_old[0] ** 2 + v_old[1] ** 2) ** (1 / 2)

    def f_2(k):
        return f(x0 + k * v_old[0] / norm_v_old, y0 + k * v_old[1] / norm_v_old)

    k = razon_aurea_maximizar(f_2, -1.5, 1.5, prec)
    x1, y1 = x0 + k * v_old[0] / norm_v_old, y0 + k * v_old[1] / norm_v_old
    plt.plot(x1, y1, 'r.')
    plt.arrow(x0, y0, x1 - x0, y1 - y0, length_includes_head=True, head_width=0.1, head_length=0.05, color='k')
    err = ((x1 - x0) ** 2 + (y1 - y0) ** 2) ** (1 / 2)
    x0, y0 = x1, y1
    v_mixed = np.array(v_old)
    cont = 1
    while err > prec:
        v2 = np.array(gradiente_diferencias_centradas(f, x0, y0))
        norm_v2 = (v2[0] ** 2 + v2[1] ** 2) ** (1 / 2)
        beta = norm_v2 ** 2 / norm_v_old ** 2  # Formula de Fletcher-Reeves
        v = v2 + beta * v_mixed
        norm_v = (v[0] ** 2 + v[1] ** 2) ** (1 / 2)

        def f_2(k):
            return f(x0 + k * v[0] / norm_v, y0 + k * v[1] / norm_v)

        k = razon_aurea_maximizar(f_2, -1.5, 1.5,
                                  prec)  # Los valores de x1 y x4 hay que "tunearlos" dependiendo de la estimaci√≥n inicial.
        x1, y1 = x0 + k * v[0] / norm_v, y0 + k * v[1] / norm_v  # M√°ximo en la direcci√≥n
        plt.plot(x1, y1, 'r.')
        plt.arrow(x0, y0, x1 - x0, y1 - y0, length_includes_head=True, head_width=0.1, head_length=0.05, color='k')
        err = ((x1 - x0) ** 2 + (y1 - y0) ** 2) ** (1 / 2)
        norm_v_old = norm_v2
        v_mixed = v
        x0, y0 = x1, y1
        cont += 1
    print('Se han necesitado', str(cont), 'iteraciones para llegar al m√°ximo:')
    print('x=', x1, ' , y=', y1, sep="")
    print()
    return x1, y1


# Utilizamos la misma estimaci√≥n que en el apartado 5
x0, y0 = 1.5, -0.5
# Repetimos el plot de densidad
plt.imshow(f_z(x_prima, y_prima).T, cmap='terrain', extent=(-3, 3, -3, 3), origin='lower')
plt.plot(x0, y0, 'b.')
plt.colorbar()
xf, yf = gradiente_conjugado_fletcher_reeves(f_z_3, x0, y0, eps)
plt.plot(xf, yf, 'g.')
plt.title('Gradiente conjugado Fletcher-Reeves')
plt.show()
print(xf, yf)

"""
Hemos necesitado una iteraci√≥n m√°s que en el caso del m√©todo de la m√°xima pendiente para el
mismo punto inicial. Veamos ahora qu√© pasa para los mismo puntos iniciales que en el apartado 6.
"""
# Repetimos el apartado anterior con puntos en torno al origen
# para alcanzar el resto de m√°ximos relativos
x0, y0 = 0, 0
x01, y01 = 0.1, 0
x02, y02 = -0.1, 0
x03, y03 = 0, 0.1
x04, y04 = 0, -0.1
x05, y05 = -0.1, 0.1
plt.imshow(f_z(x_prima, y_prima).T, cmap='terrain', extent=(-3, 3, -3, 3), origin='lower')
plt.plot(x0, y0, 'b.')
plt.plot(x01, y01, 'b.')
plt.plot(x02, y02, 'b.')
plt.plot(x03, y03, 'b.')
plt.plot(x04, y04, 'b.')
plt.plot(x05, y05, 'b.')
plt.colorbar()
xf, yf = gradiente_conjugado_fletcher_reeves(f_z_3, x0, y0, eps)
plt.plot(xf, yf, 'g.')
xf, yf = gradiente_conjugado_fletcher_reeves(f_z_3, x01, y01, eps)
plt.plot(xf, yf, 'g.')
xf, yf = gradiente_conjugado_fletcher_reeves(f_z_3, x02, y02, eps)
plt.plot(xf, yf, 'g.')
xf, yf = gradiente_conjugado_fletcher_reeves(f_z_3, x03, y03, eps)
plt.plot(xf, yf, 'g.')
xf, yf = gradiente_conjugado_fletcher_reeves(f_z_3, x04, y04, eps)
plt.plot(xf, yf, 'g.')
xf, yf = gradiente_conjugado_fletcher_reeves(f_z_3, x05, y05, eps)
plt.plot(xf, yf, 'g.')
plt.title('Gradiente conjugado Fletcher-Reeves')
plt.show()


def gradiente_conjugado_polak_ribiere(f, x0, y0, prec):
    err = 1
    v_old = gradiente_diferencias_centradas(f, x0, y0)
    norm_v_old = (v_old[0] ** 2 + v_old[1] ** 2) ** (1 / 2)

    def f_2(k):
        return f(x0 + k * v_old[0] / norm_v_old, y0 + k * v_old[1] / norm_v_old)

    k = razon_aurea_maximizar(f_2, -1.5, 1.5, prec)
    x1, y1 = x0 + k * v_old[0] / norm_v_old, y0 + k * v_old[1] / norm_v_old
    plt.plot(x1, y1, 'r.')
    plt.arrow(x0, y0, x1 - x0, y1 - y0, length_includes_head=True, head_width=0.1, head_length=0.05, color='k')
    err = ((x1 - x0) ** 2 + (y1 - y0) ** 2) ** (1 / 2)
    x0, y0 = x1, y1
    v_mixed = np.array(v_old)
    cont = 1
    while err > prec:
        v2 = np.array(gradiente_diferencias_centradas(f, x0, y0))
        norm_v2 = (v2[0] ** 2 + v2[1] ** 2) ** (1 / 2)
        beta = np.dot(v2, v2 - v_old) / norm_v_old ** 2  # F√≥rmula de Polak-Ribiere
        v = v2 + beta * v_mixed
        norm_v = (v[0] ** 2 + v[1] ** 2) ** (1 / 2)

        def f_2(k):
            return f(x0 + k * v[0] / norm_v, y0 + k * v[1] / norm_v)

        k = razon_aurea_maximizar(f_2, -1.5, 1.5,
                                  prec)  # Los valores de x1 y x4 hay que "tunearlos" dependiendo de la estimaci√≥n inicial.
        x1, y1 = x0 + k * v[0] / norm_v, y0 + k * v[1] / norm_v  # M√°ximo en la direcci√≥n
        plt.plot(x1, y1, 'r.')
        plt.arrow(x0, y0, x1 - x0, y1 - y0, length_includes_head=True, head_width=0.1, head_length=0.05, color='k')
        err = ((x1 - x0) ** 2 + (y1 - y0) ** 2) ** (1 / 2)
        norm_v_old = norm_v2
        v_mixed = v
        x0, y0 = x1, y1
        cont += 1
    print('Se han necesitado', str(cont), 'iteraciones para llegar al m√°ximo:')
    print('x=', x1, ' , y=', y1, sep="")
    print()
    return x1, y1


# Utilizamos la misma estimaci√≥n que en el apartado 5
x0, y0 = 1.5, -0.5
# Repetimos el plot de densidad
plt.imshow(f_z(x_prima, y_prima).T, cmap='terrain', extent=(-3, 3, -3, 3), origin='lower')
plt.plot(x0, y0, 'b.')
plt.colorbar()
xf, yf = gradiente_conjugado_polak_ribiere(f_z_3, x0, y0, eps)
plt.plot(xf, yf, 'g.')
plt.title('Gradiente conjugado Polak-Ribi√®re')
plt.show()
print('Gradiente conjugado Polak-Ribi√®re', xf, yf)

"""
Volvemos a necesitar una iteraci√≥n m√°s que con el m√©todo de la m√°xima pendiente, ¬øqu√© ocurrir√°
al partir de los puntos iniciales del apartado 6?
"""
# Repetimos el apartado anterior con puntos en torno al origen
# para alcanzar el resto de m√°ximos relativos
x0, y0 = 0, 0
x01, y01 = 0.1, 0
x02, y02 = -0.1, 0
x03, y03 = 0, 0.1
x04, y04 = 0, -0.1
x05, y05 = -0.1, 0.1
plt.imshow(f_z(x_prima, y_prima).T, cmap='terrain', extent=(-3, 3, -3, 3), origin='lower')
plt.plot(x0, y0, 'b.')
plt.plot(x01, y01, 'b.')
plt.plot(x02, y02, 'b.')
plt.plot(x03, y03, 'b.')
plt.plot(x04, y04, 'b.')
plt.plot(x05, y05, 'b.')
plt.colorbar()
xf, yf = gradiente_conjugado_polak_ribiere(f_z_3, x0, y0, eps)
plt.plot(xf, yf, 'g.')
xf, yf = gradiente_conjugado_polak_ribiere(f_z_3, x01, y01, eps)
plt.plot(xf, yf, 'g.')
xf, yf = gradiente_conjugado_polak_ribiere(f_z_3, x02, y02, eps)
plt.plot(xf, yf, 'g.')
xf, yf = gradiente_conjugado_polak_ribiere(f_z_3, x03, y03, eps)
plt.plot(xf, yf, 'g.')
xf, yf = gradiente_conjugado_polak_ribiere(f_z_3, x04, y04, eps)
plt.plot(xf, yf, 'g.')
xf, yf = gradiente_conjugado_polak_ribiere(f_z_3, x05, y05, eps)
plt.plot(xf, yf, 'g.')
plt.title('Gradiente conjugado Polak-Ribi√®re')
plt.show()
"""
En todos los casos se mejora el n√∫mero de iteraciones del m√©todo de la m√°xima pendiente, excepto
en un caso en el que se iguala la convergencia. Este es un buen ejemplo de que dependiendo del
problema, un m√©todo puede ser adecuado y otro no.
"""
